hydra:
  run: 
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}/${hydra.job.name}_${description}
  
description: x3d_trans

csi: csi_sign_language
transform: torchvision.transforms
T: torchvision.transforms
CT: csi_sign_language.data.transforms

phoenix14_root: preprocessed/ph14_lmdb

seed: 3407
device: cuda
epoch: 80
#-1 when we don want message out
message_interval: 100
non_block: False
pin_memory: False
num_workers: 10
batch_size: 2
vocab_size: 1296

#if continuos read model
load_weights: True
is_resume: False
checkpoint: /home/jingyan/Documents/sign_language_rgb/outputs/train/2024-03-26_15-17-40/train_x3d_trans/checkpoint.pt

model:
  _target_: ${csi}.models.slr_ctc_baseline.SLRModel
  loss_temp: 8
  loss_weight: [1.0, 0., 0.]
  backbone: 
    _target_: ${csi}.modules.slr_base.base_stream.BaseStream
    encoder: 
      _target_: ${csi}.modules.slr_base.vitpose_encoder.VitPoseEncoder
      img_size: 192
      color_range: [0, 1]
      cfg_path: resources/vitpose/td-hm_ViTPose-small_8xb64-210e_coco-256x192.py
      checkpoint: resources/vitpose/td-hm_ViTPose-small_8xb64-210e_coco-256x192-62d7a712_20230314.pth
      drop_path_rate: 0.5
      freeze_vitpose: False
    neck:
      _target_: ${csi}.modules.tconv.TemporalConv1D
      input_size: 384
      out_size: 1024
      bottleneck_size:  512
      conv_type: ['K5', 'P2', 'K5', 'P2']
    decoder:
      _target_: ${csi}.modules.slr_base.decoders.TransformerDecoder
      n_class: ${vocab_size}
      d_model: 1024
      n_heads: 8
      n_layers: 6
      d_feedforward: 2048
optimizer:
  _target_: torch.optim.Adam
  lr: 1e-4
  weight_decay: 0.0001

lr_scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 15
  gamma: 0.5

trainner:
  _target_: ${csi}.engines.trainner.Trainner
  device: ${device}
  message_interval: ${message_interval}

inferencer:
  _target_: ${csi}.engines.inferencer.Inferencer
  device: ${device}

data:
  # excluded: ["13April_2011_Wednesday_tagesschau_default-14",]
  subset: multisigner
  collate_fn: 
    _target_: ${csi}.data.dataset.phoenix14.CollateFn

  transform_train: 
        _target_: ${T}.Compose
        transforms: 
          #process video data
        - _target_: ${CT}.common.ApplyByKey
          key: video
          transforms:
          - _target_: ${CT}.common.ToTensor
            dtype: float32
          - _target_: ${CT}.common.TemporalAug
            t_min: 0.5
            t_max: 1.5
          - _target_: ${CT}.common.Rescale
            input: [0., 255.]
            output: [0., 1.]
          - _target_: ${CT}.common.Rearrange
            pattern: "t h w c -> t c h w"
          - _target_: ${T}.RandomResizedCrop
            size: 224
            scale: [0.7, 1.0]
            ratio: [0.75, 1.33333333333]
            antialias: True
          - _target_: ${T}.Resize
            size: 192
          - _target_: ${CT}.t_tensor.ColorJitter
            brightness: 0.4
            contrast: 0.4
            saturation: 0.4
            hue: 0.1
            p: 0.5
          #process gloss data
        - _target_: ${CT}.common.ApplyByKey
          key: gloss
          transforms:
          - _target_: ${CT}.common.ToTensor

  transform_val: 
        _target_: ${T}.Compose
        transforms: 
        - _target_: ${CT}.common.ApplyByKey
          key: video
          transforms:
          - _target_: ${CT}.common.ToTensor
            dtype: float32
          - _target_: ${CT}.common.Rearrange
            pattern: "t h w c -> t c h w"
          - _target_: ${CT}.common.Rescale
            input: [0., 255.]
            output: [0., 1.]
          - _target_: ${T}.CenterCrop
            size: 224
          - _target_: ${T}.Resize
            size: 192
          # - _target_: ${CT}.common.Rearrange
          #   pattern: "t c h w -> t h w c"
        - _target_: ${CT}.common.ApplyByKey
          key: gloss
          transforms:
          - _target_: ${CT}.common.ToTensor
    
  train_set: 
    _target_: ${csi}.data.dataset.phoenix14.MyPhoenix14Dataset
    data_root: ${phoenix14_root}
    subset: ${data.subset}
    mode: train
    transform: ${data.transform_train}

  val_set: 
    _target_: ${csi}.data.dataset.phoenix14.MyPhoenix14Dataset
    data_root: ${phoenix14_root}
    subset: ${data.subset}
    mode: dev
    transform: ${data.transform_val}


  train_loader:
    _target_: torch.utils.data.DataLoader
    batch_size: ${batch_size}
    num_workers: ${num_workers}
    pin_memory: ${pin_memory}
    shuffle: true
    dataset: ${data.train_set}
    collate_fn: ${data.collate_fn}

  val_loader:
    _target_: torch.utils.data.DataLoader
    batch_size: ${batch_size}
    num_workers: ${num_workers}
    pin_memory: ${pin_memory}
    dataset: ${data.val_set}
    collate_fn: ${data.collate_fn}
