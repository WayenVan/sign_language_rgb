WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'run/train/resnet_trans_ddp': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'run/train/resnet_trans_ddp': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
[2024-03-30 06:09:38,861][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2024-03-30 06:09:38,861][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 1
[2024-03-30 06:09:38,861][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024-03-30 06:09:38,861][torch.distributed.distributed_c10d][INFO] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
True
False
[2024-03-30 06:09:38,862][main][INFO] - saving git info
Git diff output saved to outputs/train_ddp/2024-03-30_06-09-38/changes.patch
[2024-03-30 06:09:38,886][main][INFO] - building model and dataloaders
[2024-03-30 06:09:39,994][torch.distributed.nn.jit.instantiator][INFO] - Created a temporary directory at /tmp/tmpy0d2fgvs
[2024-03-30 06:09:39,994][torch.distributed.nn.jit.instantiator][INFO] - Writing /tmp/tmpy0d2fgvs/_remote_module_non_scriptable.py
[2024-03-30 06:09:39,994][torch.distributed.nn.jit.instantiator][INFO] - Created a temporary directory at /tmp/tmpsmda2mbz
[2024-03-30 06:09:39,994][torch.distributed.nn.jit.instantiator][INFO] - Writing /tmp/tmpsmda2mbz/_remote_module_non_scriptable.py
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
Loads checkpoint by local backend from path: resources/resnet/resnet18_8xb32_in1k_20210831-fbbb1da6.pth
[2024-03-30 06:09:43,338][main][INFO] - epoch 0, lr=[0.0001]
  0%|          | 0/2836 [00:00<?, ?it/s]  0%|          | 0/2836 [00:00<?, ?it/s]/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/2836 [00:03<2:23:18,  3.03s/it][2024-03-30 06:09:46,428][main.Trainner][INFO] - max memory: 2171090944, memory: 1363976704
[2024-03-30 06:09:46,430][main.Trainner][INFO] - iteration index: 0, batch loss: 119.57241821289062
  0%|          | 1/2836 [00:03<2:25:59,  3.09s/it]  0%|          | 2/2836 [00:03<1:12:38,  1.54s/it]  0%|          | 2/2836 [00:03<1:13:07,  1.55s/it]  0%|          | 3/2836 [00:04<50:17,  1.07s/it]    0%|          | 3/2836 [00:04<50:02,  1.06s/it]    0%|          | 4/2836 [00:04<39:20,  1.20it/s]  0%|          | 4/2836 [00:04<39:30,  1.19it/s]  0%|          | 5/2836 [00:04<32:26,  1.45it/s]  0%|          | 5/2836 [00:04<32:32,  1.45it/s]  0%|          | 6/2836 [00:05<27:32,  1.71it/s]  0%|          | 6/2836 [00:05<27:28,  1.72it/s]  0%|          | 7/2836 [00:05<24:07,  1.95it/s]  0%|          | 7/2836 [00:05<24:05,  1.96it/s]  0%|          | 8/2836 [00:06<22:37,  2.08it/s]  0%|          | 8/2836 [00:06<22:39,  2.08it/s]  0%|          | 9/2836 [00:06<22:32,  2.09it/s]  0%|          | 9/2836 [00:06<22:34,  2.09it/s]  0%|          | 10/2836 [00:07<22:06,  2.13it/s]  0%|          | 10/2836 [00:07<22:05,  2.13it/s]  0%|          | 11/2836 [00:07<21:41,  2.17it/s]  0%|          | 11/2836 [00:07<21:44,  2.17it/s]  0%|          | 12/2836 [00:07<21:19,  2.21it/s]  0%|          | 12/2836 [00:07<21:20,  2.20it/s]  0%|          | 13/2836 [00:08<20:41,  2.27it/s]  0%|          | 13/2836 [00:08<20:42,  2.27it/s]  0%|          | 14/2836 [00:08<20:22,  2.31it/s]  0%|          | 14/2836 [00:08<20:23,  2.31it/s]  1%|          | 15/2836 [00:09<19:56,  2.36it/s]  1%|          | 15/2836 [00:09<19:57,  2.36it/s]  1%|          | 16/2836 [00:09<19:57,  2.36it/s]  1%|          | 16/2836 [00:09<19:56,  2.36it/s]  1%|          | 17/2836 [00:09<19:40,  2.39it/s]  1%|          | 17/2836 [00:09<19:40,  2.39it/s]  1%|          | 18/2836 [00:10<19:26,  2.41it/s]  1%|          | 18/2836 [00:10<19:26,  2.41it/s]  1%|          | 19/2836 [00:10<19:37,  2.39it/s]  1%|          | 19/2836 [00:10<19:37,  2.39it/s]  1%|          | 20/2836 [00:11<19:09,  2.45it/s]  1%|          | 20/2836 [00:11<19:10,  2.45it/s]  1%|          | 21/2836 [00:11<18:22,  2.55it/s]  1%|          | 21/2836 [00:11<18:22,  2.55it/s]  1%|          | 22/2836 [00:11<18:32,  2.53it/s]  1%|          | 22/2836 [00:11<18:32,  2.53it/s]  1%|          | 23/2836 [00:12<18:56,  2.47it/s]  1%|          | 23/2836 [00:12<18:57,  2.47it/s]  1%|          | 24/2836 [00:12<19:14,  2.44it/s]  1%|          | 24/2836 [00:12<19:14,  2.44it/s]  1%|          | 25/2836 [00:13<19:28,  2.41it/s]  1%|          | 25/2836 [00:13<19:28,  2.41it/s]  1%|          | 26/2836 [00:13<19:29,  2.40it/s]  1%|          | 26/2836 [00:13<19:29,  2.40it/s]  1%|          | 27/2836 [00:14<18:52,  2.48it/s]  1%|          | 27/2836 [00:14<18:52,  2.48it/s]  1%|          | 28/2836 [00:14<18:16,  2.56it/s]  1%|          | 28/2836 [00:14<18:16,  2.56it/s]  1%|          | 29/2836 [00:14<19:11,  2.44it/s]  1%|          | 29/2836 [00:14<19:11,  2.44it/s]  1%|          | 30/2836 [00:15<19:36,  2.38it/s]  1%|          | 30/2836 [00:15<19:48,  2.36it/s]  1%|          | 31/2836 [00:15<20:37,  2.27it/s]  1%|          | 31/2836 [00:15<20:40,  2.26it/s]  1%|          | 32/2836 [00:16<20:10,  2.32it/s]  1%|          | 32/2836 [00:16<20:08,  2.32it/s]  1%|          | 33/2836 [00:16<19:20,  2.41it/s]  1%|          | 33/2836 [00:16<19:20,  2.42it/s]  1%|          | 34/2836 [00:16<19:02,  2.45it/s]  1%|          | 34/2836 [00:16<19:01,  2.46it/s]  1%|          | 35/2836 [00:17<19:37,  2.38it/s]  1%|          | 35/2836 [00:17<19:38,  2.38it/s]  1%|▏         | 36/2836 [00:17<19:51,  2.35it/s]  1%|▏         | 36/2836 [00:17<19:50,  2.35it/s]  1%|▏         | 37/2836 [00:18<19:49,  2.35it/s]  1%|▏         | 37/2836 [00:18<19:50,  2.35it/s]  1%|▏         | 38/2836 [00:18<20:01,  2.33it/s]  1%|▏         | 38/2836 [00:18<20:02,  2.33it/s]  1%|▏         | 39/2836 [00:19<19:15,  2.42it/s]  1%|▏         | 39/2836 [00:19<19:16,  2.42it/s]  1%|▏         | 40/2836 [00:19<19:02,  2.45it/s]  1%|▏         | 40/2836 [00:19<19:02,  2.45it/s]  1%|▏         | 41/2836 [00:19<18:27,  2.52it/s]  1%|▏         | 41/2836 [00:19<18:27,  2.52it/s]  1%|▏         | 42/2836 [00:20<17:49,  2.61it/s]  1%|▏         | 42/2836 [00:20<17:48,  2.61it/s]  2%|▏         | 43/2836 [00:20<18:20,  2.54it/s]  2%|▏         | 43/2836 [00:20<18:21,  2.54it/s]  2%|▏         | 44/2836 [00:20<17:16,  2.69it/s]  2%|▏         | 44/2836 [00:20<17:16,  2.69it/s]  2%|▏         | 45/2836 [00:21<17:44,  2.62it/s]  2%|▏         | 45/2836 [00:21<17:56,  2.59it/s]  2%|▏         | 46/2836 [00:21<17:39,  2.63it/s]  2%|▏         | 46/2836 [00:21<17:42,  2.62it/s]  2%|▏         | 47/2836 [00:22<16:53,  2.75it/s]  2%|▏         | 47/2836 [00:22<16:55,  2.75it/s]  2%|▏         | 48/2836 [00:22<16:58,  2.74it/s]  2%|▏         | 48/2836 [00:22<17:00,  2.73it/s]  2%|▏         | 49/2836 [00:22<17:24,  2.67it/s]  2%|▏         | 49/2836 [00:22<17:23,  2.67it/s]  2%|▏         | 50/2836 [00:23<17:02,  2.73it/s]  2%|▏         | 50/2836 [00:23<17:03,  2.72it/s]  2%|▏         | 51/2836 [00:23<17:07,  2.71it/s]  2%|▏         | 51/2836 [00:23<17:08,  2.71it/s]  2%|▏         | 52/2836 [00:23<17:00,  2.73it/s]  2%|▏         | 52/2836 [00:23<17:00,  2.73it/s]  2%|▏         | 53/2836 [00:24<17:17,  2.68it/s]  2%|▏         | 53/2836 [00:24<17:17,  2.68it/s]  2%|▏         | 54/2836 [00:24<17:47,  2.61it/s]  2%|▏         | 54/2836 [00:24<17:47,  2.61it/s]  2%|▏         | 55/2836 [00:25<18:17,  2.53it/s]  2%|▏         | 55/2836 [00:25<18:17,  2.53it/s]  2%|▏         | 56/2836 [00:25<19:02,  2.43it/s]  2%|▏         | 56/2836 [00:25<19:03,  2.43it/s]  2%|▏         | 57/2836 [00:25<19:07,  2.42it/s]  2%|▏         | 57/2836 [00:25<19:18,  2.40it/s]  2%|▏         | 58/2836 [00:26<18:55,  2.45it/s]  2%|▏         | 58/2836 [00:26<18:52,  2.45it/s]  2%|▏         | 59/2836 [00:26<19:12,  2.41it/s]  2%|▏         | 59/2836 [00:26<19:10,  2.41it/s]  2%|▏         | 60/2836 [00:27<19:19,  2.39it/s]  2%|▏         | 60/2836 [00:27<19:28,  2.37it/s]  2%|▏         | 61/2836 [00:27<18:58,  2.44it/s]  2%|▏         | 61/2836 [00:27<19:02,  2.43it/s]  2%|▏         | 62/2836 [00:27<18:15,  2.53it/s]  2%|▏         | 62/2836 [00:27<18:12,  2.54it/s]  2%|▏         | 63/2836 [00:28<17:55,  2.58it/s]  2%|▏         | 63/2836 [00:28<17:58,  2.57it/s]  2%|▏         | 64/2836 [00:28<17:50,  2.59it/s]  2%|▏         | 64/2836 [00:28<17:49,  2.59it/s]  2%|▏         | 65/2836 [00:29<18:00,  2.56it/s]  2%|▏         | 65/2836 [00:29<18:02,  2.56it/s]  2%|▏         | 66/2836 [00:29<17:55,  2.57it/s]  2%|▏         | 66/2836 [00:29<17:55,  2.58it/s]  2%|▏         | 67/2836 [00:30<20:30,  2.25it/s]  2%|▏         | 67/2836 [00:30<20:29,  2.25it/s]  2%|▏         | 68/2836 [00:30<19:24,  2.38it/s]  2%|▏         | 68/2836 [00:30<19:23,  2.38it/s]  2%|▏         | 69/2836 [00:30<18:47,  2.45it/s]  2%|▏         | 69/2836 [00:30<18:48,  2.45it/s]  2%|▏         | 70/2836 [00:31<17:41,  2.61it/s]  2%|▏         | 70/2836 [00:31<17:41,  2.61it/s]  3%|▎         | 71/2836 [00:31<17:56,  2.57it/s]  3%|▎         | 71/2836 [00:31<18:07,  2.54it/s]  3%|▎         | 72/2836 [00:32<18:56,  2.43it/s]  3%|▎         | 72/2836 [00:32<19:00,  2.42it/s]  3%|▎         | 73/2836 [00:32<18:19,  2.51it/s]  3%|▎         | 73/2836 [00:32<18:21,  2.51it/s]  3%|▎         | 74/2836 [00:32<17:56,  2.57it/s]  3%|▎         | 74/2836 [00:32<17:58,  2.56it/s]  3%|▎         | 75/2836 [00:33<17:53,  2.57it/s]  3%|▎         | 75/2836 [00:33<17:52,  2.57it/s]  3%|▎         | 76/2836 [00:33<17:17,  2.66it/s]  3%|▎         | 76/2836 [00:33<17:18,  2.66it/s]  3%|▎         | 77/2836 [00:33<17:22,  2.65it/s]  3%|▎         | 77/2836 [00:33<17:21,  2.65it/s]  3%|▎         | 78/2836 [00:34<18:44,  2.45it/s]  3%|▎         | 78/2836 [00:34<18:44,  2.45it/s]  3%|▎         | 79/2836 [00:34<18:22,  2.50it/s]  3%|▎         | 79/2836 [00:34<18:22,  2.50it/s]  3%|▎         | 80/2836 [00:35<17:55,  2.56it/s]  3%|▎         | 80/2836 [00:35<17:54,  2.56it/s]  3%|▎         | 81/2836 [00:35<17:11,  2.67it/s]  3%|▎         | 81/2836 [00:35<17:12,  2.67it/s]  3%|▎         | 82/2836 [00:35<16:57,  2.71it/s]  3%|▎         | 82/2836 [00:35<16:59,  2.70it/s]  3%|▎         | 83/2836 [00:36<17:14,  2.66it/s]  3%|▎         | 83/2836 [00:36<17:15,  2.66it/s]  3%|▎         | 84/2836 [00:36<16:56,  2.71it/s]  3%|▎         | 84/2836 [00:36<16:57,  2.70it/s]  3%|▎         | 85/2836 [00:36<17:00,  2.70it/s]  3%|▎         | 85/2836 [00:36<17:00,  2.70it/s]  3%|▎         | 86/2836 [00:37<17:29,  2.62it/s]  3%|▎         | 86/2836 [00:37<17:40,  2.59it/s]  3%|▎         | 87/2836 [00:37<17:37,  2.60it/s]  3%|▎         | 87/2836 [00:37<17:35,  2.60it/s]  3%|▎         | 88/2836 [00:38<18:31,  2.47it/s]  3%|▎         | 88/2836 [00:38<18:29,  2.48it/s]  3%|▎         | 89/2836 [00:38<18:09,  2.52it/s]  3%|▎         | 89/2836 [00:38<18:11,  2.52it/s]  3%|▎         | 90/2836 [00:38<17:18,  2.65it/s]  3%|▎         | 90/2836 [00:38<17:19,  2.64it/s]  3%|▎         | 91/2836 [00:39<17:43,  2.58it/s]  3%|▎         | 91/2836 [00:39<17:44,  2.58it/s]  3%|▎         | 92/2836 [00:39<17:07,  2.67it/s]  3%|▎         | 92/2836 [00:39<17:06,  2.67it/s]  3%|▎         | 93/2836 [00:40<17:21,  2.63it/s]  3%|▎         | 93/2836 [00:40<17:21,  2.63it/s]  3%|▎         | 94/2836 [00:40<17:19,  2.64it/s]  3%|▎         | 94/2836 [00:40<17:19,  2.64it/s]  3%|▎         | 95/2836 [00:40<17:25,  2.62it/s]  3%|▎         | 95/2836 [00:40<17:26,  2.62it/s]  3%|▎         | 96/2836 [00:41<18:23,  2.48it/s]  3%|▎         | 96/2836 [00:41<18:23,  2.48it/s]  3%|▎         | 97/2836 [00:41<18:01,  2.53it/s]  3%|▎         | 97/2836 [00:41<18:01,  2.53it/s]  3%|▎         | 98/2836 [00:41<17:50,  2.56it/s]  3%|▎         | 98/2836 [00:41<17:50,  2.56it/s]  3%|▎         | 99/2836 [00:42<17:49,  2.56it/s]  3%|▎         | 99/2836 [00:42<17:49,  2.56it/s]  4%|▎         | 100/2836 [00:42<17:19,  2.63it/s]  4%|▎         | 100/2836 [00:42<17:20,  2.63it/s][2024-03-30 06:10:26,449][main.Trainner][INFO] - max memory: 3950599680, memory: 1366159360
  4%|▎         | 101/2836 [00:43<17:14,  2.64it/s][2024-03-30 06:10:26,458][main.Trainner][INFO] - iteration index: 100, batch loss: 69.121826171875
  4%|▎         | 101/2836 [00:43<17:14,  2.64it/s]  4%|▎         | 102/2836 [00:43<17:58,  2.53it/s]  4%|▎         | 102/2836 [00:43<17:58,  2.53it/s]  4%|▎         | 103/2836 [00:43<17:55,  2.54it/s]  4%|▎         | 103/2836 [00:43<17:55,  2.54it/s]  4%|▎         | 104/2836 [00:44<17:11,  2.65it/s]  4%|▎         | 104/2836 [00:44<17:11,  2.65it/s]  4%|▎         | 105/2836 [00:44<16:18,  2.79it/s]  4%|▎         | 105/2836 [00:44<16:18,  2.79it/s]  4%|▎         | 106/2836 [00:45<17:13,  2.64it/s]  4%|▎         | 106/2836 [00:45<17:13,  2.64it/s]  4%|▍         | 107/2836 [00:45<15:46,  2.88it/s]  4%|▍         | 107/2836 [00:45<15:46,  2.88it/s]  4%|▍         | 108/2836 [00:45<15:51,  2.87it/s]  4%|▍         | 108/2836 [00:45<15:51,  2.87it/s]  4%|▍         | 109/2836 [00:46<15:55,  2.85it/s]  4%|▍         | 109/2836 [00:46<16:07,  2.82it/s]  4%|▍         | 110/2836 [00:46<16:26,  2.76it/s]  4%|▍         | 110/2836 [00:46<16:30,  2.75it/s]  4%|▍         | 111/2836 [00:46<16:27,  2.76it/s]  4%|▍         | 111/2836 [00:46<16:29,  2.75it/s]  4%|▍         | 112/2836 [00:47<16:25,  2.76it/s]  4%|▍         | 112/2836 [00:47<16:27,  2.76it/s]  4%|▍         | 113/2836 [00:47<17:14,  2.63it/s]  4%|▍         | 113/2836 [00:47<17:13,  2.63it/s]  4%|▍         | 114/2836 [00:47<17:02,  2.66it/s]  4%|▍         | 114/2836 [00:47<17:03,  2.66it/s]  4%|▍         | 115/2836 [00:48<17:22,  2.61it/s]  4%|▍         | 115/2836 [00:48<17:22,  2.61it/s]  4%|▍         | 116/2836 [00:48<16:27,  2.75it/s]  4%|▍         | 116/2836 [00:48<16:27,  2.76it/s]  4%|▍         | 117/2836 [00:48<15:56,  2.84it/s]  4%|▍         | 117/2836 [00:48<15:56,  2.84it/s]  4%|▍         | 118/2836 [00:49<15:13,  2.98it/s]  4%|▍         | 118/2836 [00:49<15:13,  2.98it/s]  4%|▍         | 119/2836 [00:49<16:10,  2.80it/s]  4%|▍         | 119/2836 [00:49<16:11,  2.80it/s]  4%|▍         | 120/2836 [00:50<17:32,  2.58it/s]  4%|▍         | 120/2836 [00:50<17:32,  2.58it/s]  4%|▍         | 121/2836 [00:50<17:55,  2.52it/s]  4%|▍         | 121/2836 [00:50<17:56,  2.52it/s]  4%|▍         | 122/2836 [00:50<17:58,  2.52it/s]  4%|▍         | 122/2836 [00:50<18:01,  2.51it/s]  4%|▍         | 123/2836 [00:51<17:58,  2.52it/s]  4%|▍         | 123/2836 [00:51<17:58,  2.52it/s]  4%|▍         | 124/2836 [00:51<16:37,  2.72it/s]  4%|▍         | 124/2836 [00:51<16:37,  2.72it/s]  4%|▍         | 125/2836 [00:51<16:31,  2.73it/s]  4%|▍         | 125/2836 [00:51<16:32,  2.73it/s]  4%|▍         | 126/2836 [00:52<17:02,  2.65it/s]  4%|▍         | 126/2836 [00:52<17:03,  2.65it/s]  4%|▍         | 127/2836 [00:52<16:07,  2.80it/s]  4%|▍         | 127/2836 [00:52<16:07,  2.80it/s]  5%|▍         | 128/2836 [00:53<16:44,  2.70it/s]  5%|▍         | 128/2836 [00:53<16:44,  2.70it/s]  5%|▍         | 129/2836 [00:53<17:09,  2.63it/s]  5%|▍         | 129/2836 [00:53<17:09,  2.63it/s]  5%|▍         | 130/2836 [00:53<17:08,  2.63it/s]  5%|▍         | 130/2836 [00:53<17:08,  2.63it/s]  5%|▍         | 131/2836 [00:54<17:43,  2.54it/s]  5%|▍         | 131/2836 [00:54<17:43,  2.54it/s]  5%|▍         | 132/2836 [00:54<17:31,  2.57it/s]  5%|▍         | 132/2836 [00:54<17:33,  2.57it/s]  5%|▍         | 133/2836 [00:55<17:18,  2.60it/s]  5%|▍         | 133/2836 [00:55<17:19,  2.60it/s]  5%|▍         | 134/2836 [00:55<16:40,  2.70it/s]  5%|▍         | 134/2836 [00:55<16:42,  2.70it/s]  5%|▍         | 135/2836 [00:55<17:24,  2.59it/s]  5%|▍         | 135/2836 [00:55<17:26,  2.58it/s]  5%|▍         | 136/2836 [00:56<18:44,  2.40it/s]  5%|▍         | 136/2836 [00:56<18:44,  2.40it/s]  5%|▍         | 137/2836 [00:56<17:27,  2.58it/s]  5%|▍         | 137/2836 [00:56<17:27,  2.58it/s]  5%|▍         | 138/2836 [00:57<17:29,  2.57it/s]  5%|▍         | 138/2836 [00:57<17:30,  2.57it/s]  5%|▍         | 139/2836 [00:57<16:12,  2.77it/s]  5%|▍         | 139/2836 [00:57<16:12,  2.77it/s]  5%|▍         | 140/2836 [00:57<16:26,  2.73it/s]  5%|▍         | 140/2836 [00:57<16:38,  2.70it/s]  5%|▍         | 141/2836 [00:58<17:41,  2.54it/s]  5%|▍         | 141/2836 [00:58<17:38,  2.55it/s]  5%|▌         | 142/2836 [00:58<17:40,  2.54it/s]  5%|▌         | 142/2836 [00:58<17:37,  2.55it/s]  5%|▌         | 143/2836 [00:58<17:43,  2.53it/s]  5%|▌         | 143/2836 [00:58<17:42,  2.53it/s]  5%|▌         | 144/2836 [00:59<17:57,  2.50it/s]  5%|▌         | 144/2836 [00:59<17:56,  2.50it/s]  5%|▌         | 145/2836 [00:59<18:38,  2.41it/s]  5%|▌         | 145/2836 [00:59<18:37,  2.41it/s]  5%|▌         | 146/2836 [01:00<17:46,  2.52it/s]  5%|▌         | 146/2836 [01:00<17:47,  2.52it/s]  5%|▌         | 147/2836 [01:00<17:22,  2.58it/s]  5%|▌         | 147/2836 [01:00<17:32,  2.55it/s]  5%|▌         | 148/2836 [01:00<16:53,  2.65it/s]  5%|▌         | 148/2836 [01:00<16:52,  2.65it/s]  5%|▌         | 149/2836 [01:01<17:58,  2.49it/s]  5%|▌         | 149/2836 [01:01<18:00,  2.49it/s]  5%|▌         | 150/2836 [01:01<18:19,  2.44it/s]  5%|▌         | 150/2836 [01:01<18:21,  2.44it/s]  5%|▌         | 151/2836 [01:02<17:47,  2.51it/s]  5%|▌         | 151/2836 [01:02<17:48,  2.51it/s]  5%|▌         | 152/2836 [01:02<17:21,  2.58it/s]  5%|▌         | 152/2836 [01:02<17:20,  2.58it/s]  5%|▌         | 153/2836 [01:02<16:26,  2.72it/s]  5%|▌         | 153/2836 [01:02<16:26,  2.72it/s]  5%|▌         | 154/2836 [01:03<16:43,  2.67it/s]  5%|▌         | 154/2836 [01:03<16:43,  2.67it/s]  5%|▌         | 155/2836 [01:03<17:18,  2.58it/s]  5%|▌         | 155/2836 [01:03<17:19,  2.58it/s]  6%|▌         | 156/2836 [01:04<17:04,  2.62it/s]  6%|▌         | 156/2836 [01:04<17:04,  2.62it/s]  6%|▌         | 157/2836 [01:04<17:28,  2.55it/s]  6%|▌         | 157/2836 [01:04<17:28,  2.55it/s]  6%|▌         | 158/2836 [01:04<16:29,  2.71it/s]  6%|▌         | 158/2836 [01:04<16:29,  2.71it/s]  6%|▌         | 159/2836 [01:05<16:40,  2.68it/s]  6%|▌         | 159/2836 [01:05<16:40,  2.67it/s]  6%|▌         | 160/2836 [01:05<15:42,  2.84it/s]  6%|▌         | 160/2836 [01:05<15:43,  2.84it/s]  6%|▌         | 161/2836 [01:05<15:43,  2.83it/s]  6%|▌         | 161/2836 [01:05<15:49,  2.82it/s]  6%|▌         | 162/2836 [01:06<16:50,  2.65it/s]  6%|▌         | 162/2836 [01:06<16:59,  2.62it/s]  6%|▌         | 163/2836 [01:06<16:43,  2.66it/s]  6%|▌         | 163/2836 [01:06<16:39,  2.67it/s]  6%|▌         | 164/2836 [01:06<16:54,  2.63it/s]  6%|▌         | 164/2836 [01:06<16:51,  2.64it/s]  6%|▌         | 165/2836 [01:07<16:33,  2.69it/s]  6%|▌         | 165/2836 [01:07<16:31,  2.69it/s]  6%|▌         | 166/2836 [01:07<16:24,  2.71it/s]  6%|▌         | 166/2836 [01:07<16:23,  2.72it/s]  6%|▌         | 167/2836 [01:08<15:58,  2.79it/s]  6%|▌         | 167/2836 [01:08<15:57,  2.79it/s]  6%|▌         | 168/2836 [01:08<16:13,  2.74it/s]  6%|▌         | 168/2836 [01:08<16:13,  2.74it/s]  6%|▌         | 169/2836 [01:08<15:34,  2.86it/s]  6%|▌         | 169/2836 [01:08<15:33,  2.86it/s]  6%|▌         | 170/2836 [01:09<15:16,  2.91it/s]  6%|▌         | 170/2836 [01:09<15:15,  2.91it/s]  6%|▌         | 171/2836 [01:09<15:15,  2.91it/s]  6%|▌         | 171/2836 [01:09<15:14,  2.91it/s]  6%|▌         | 172/2836 [01:09<15:37,  2.84it/s]  6%|▌         | 172/2836 [01:09<15:37,  2.84it/s]  6%|▌         | 173/2836 [01:10<16:05,  2.76it/s]  6%|▌         | 173/2836 [01:10<16:05,  2.76it/s]  6%|▌         | 174/2836 [01:10<16:52,  2.63it/s]  6%|▌         | 174/2836 [01:10<16:52,  2.63it/s]  6%|▌         | 175/2836 [01:10<17:00,  2.61it/s]  6%|▌         | 175/2836 [01:10<17:00,  2.61it/s]  6%|▌         | 176/2836 [01:11<17:24,  2.55it/s]  6%|▌         | 176/2836 [01:11<17:24,  2.55it/s]  6%|▌         | 177/2836 [01:11<16:51,  2.63it/s]  6%|▌         | 177/2836 [01:11<16:51,  2.63it/s]  6%|▋         | 178/2836 [01:12<16:31,  2.68it/s]  6%|▋         | 178/2836 [01:12<16:31,  2.68it/s]  6%|▋         | 179/2836 [01:12<15:41,  2.82it/s]  6%|▋         | 179/2836 [01:12<15:42,  2.82it/s]  6%|▋         | 180/2836 [01:12<16:20,  2.71it/s]  6%|▋         | 180/2836 [01:12<16:21,  2.71it/s]  6%|▋         | 181/2836 [01:13<16:50,  2.63it/s]  6%|▋         | 181/2836 [01:13<16:50,  2.63it/s]  6%|▋         | 182/2836 [01:13<16:19,  2.71it/s]  6%|▋         | 182/2836 [01:13<16:20,  2.71it/s]  6%|▋         | 183/2836 [01:13<15:50,  2.79it/s]  6%|▋         | 183/2836 [01:13<15:50,  2.79it/s]  6%|▋         | 184/2836 [01:14<16:18,  2.71it/s]  6%|▋         | 184/2836 [01:14<16:18,  2.71it/s]  7%|▋         | 185/2836 [01:14<16:18,  2.71it/s]  7%|▋         | 185/2836 [01:14<16:20,  2.70it/s]  7%|▋         | 186/2836 [01:14<15:41,  2.81it/s]  7%|▋         | 186/2836 [01:14<15:41,  2.82it/s]  7%|▋         | 187/2836 [01:15<16:38,  2.65it/s]  7%|▋         | 187/2836 [01:15<16:38,  2.65it/s]  7%|▋         | 188/2836 [01:15<16:13,  2.72it/s]  7%|▋         | 188/2836 [01:15<16:13,  2.72it/s]  7%|▋         | 189/2836 [01:16<16:05,  2.74it/s]  7%|▋         | 189/2836 [01:16<16:04,  2.74it/s]  7%|▋         | 190/2836 [01:16<16:01,  2.75it/s]  7%|▋         | 190/2836 [01:16<16:13,  2.72it/s]  7%|▋         | 191/2836 [01:16<17:14,  2.56it/s]  7%|▋         | 191/2836 [01:16<17:22,  2.54it/s]  7%|▋         | 192/2836 [01:17<16:08,  2.73it/s]  7%|▋         | 192/2836 [01:17<16:09,  2.73it/s]  7%|▋         | 193/2836 [01:17<16:27,  2.68it/s]  7%|▋         | 193/2836 [01:17<16:28,  2.68it/s]  7%|▋         | 194/2836 [01:18<16:42,  2.64it/s]  7%|▋         | 194/2836 [01:18<16:43,  2.63it/s]  7%|▋         | 195/2836 [01:18<16:35,  2.65it/s]  7%|▋         | 195/2836 [01:18<16:36,  2.65it/s]  7%|▋         | 196/2836 [01:18<16:33,  2.66it/s]  7%|▋         | 196/2836 [01:18<16:34,  2.65it/s]  7%|▋         | 197/2836 [01:19<17:16,  2.55it/s]  7%|▋         | 197/2836 [01:19<17:16,  2.55it/s]  7%|▋         | 198/2836 [01:19<17:08,  2.56it/s]  7%|▋         | 198/2836 [01:19<17:08,  2.56it/s]  7%|▋         | 199/2836 [01:19<16:43,  2.63it/s]  7%|▋         | 199/2836 [01:19<16:43,  2.63it/s]  7%|▋         | 200/2836 [01:20<16:37,  2.64it/s]  7%|▋         | 200/2836 [01:20<16:37,  2.64it/s][2024-03-30 06:11:03,998][main.Trainner][INFO] - max memory: 3950599680, memory: 1365547008
[2024-03-30 06:11:04,008][main.Trainner][INFO] - iteration index: 200, batch loss: 82.67688751220703
  7%|▋         | 201/2836 [01:20<16:23,  2.68it/s]  7%|▋         | 201/2836 [01:20<16:23,  2.68it/s]  7%|▋         | 202/2836 [01:21<16:28,  2.66it/s]  7%|▋         | 202/2836 [01:21<16:29,  2.66it/s]  7%|▋         | 203/2836 [01:21<16:19,  2.69it/s]  7%|▋         | 203/2836 [01:21<16:20,  2.69it/s]  7%|▋         | 204/2836 [01:21<15:21,  2.86it/s]  7%|▋         | 204/2836 [01:21<15:32,  2.82it/s]  7%|▋         | 205/2836 [01:22<16:04,  2.73it/s]  7%|▋         | 205/2836 [01:22<16:05,  2.73it/s]  7%|▋         | 206/2836 [01:22<16:13,  2.70it/s]  7%|▋         | 206/2836 [01:22<16:09,  2.71it/s]  7%|▋         | 207/2836 [01:22<16:31,  2.65it/s]  7%|▋         | 207/2836 [01:22<16:34,  2.64it/s]  7%|▋         | 208/2836 [01:23<16:53,  2.59it/s]  7%|▋         | 208/2836 [01:23<16:51,  2.60it/s]  7%|▋         | 209/2836 [01:23<17:10,  2.55it/s]  7%|▋         | 209/2836 [01:23<17:12,  2.55it/s]  7%|▋         | 210/2836 [01:24<16:39,  2.63it/s]  7%|▋         | 210/2836 [01:24<16:40,  2.62it/s]  7%|▋         | 211/2836 [01:24<16:22,  2.67it/s]  7%|▋         | 211/2836 [01:24<16:22,  2.67it/s]  7%|▋         | 212/2836 [01:24<16:08,  2.71it/s]  7%|▋         | 212/2836 [01:24<16:08,  2.71it/s]  8%|▊         | 213/2836 [01:25<15:29,  2.82it/s]  8%|▊         | 213/2836 [01:25<15:30,  2.82it/s]  8%|▊         | 214/2836 [01:25<15:46,  2.77it/s]  8%|▊         | 214/2836 [01:25<15:45,  2.77it/s]  8%|▊         | 215/2836 [01:25<14:51,  2.94it/s]  8%|▊         | 215/2836 [01:25<14:52,  2.94it/s]  8%|▊         | 216/2836 [01:26<14:50,  2.94it/s]  8%|▊         | 216/2836 [01:26<14:50,  2.94it/s]  8%|▊         | 217/2836 [01:26<15:02,  2.90it/s]  8%|▊         | 217/2836 [01:26<15:02,  2.90it/s]  8%|▊         | 218/2836 [01:26<14:45,  2.96it/s]  8%|▊         | 218/2836 [01:26<14:45,  2.96it/s]  8%|▊         | 219/2836 [01:27<14:31,  3.00it/s]  8%|▊         | 219/2836 [01:27<14:34,  2.99it/s]  8%|▊         | 220/2836 [01:27<14:12,  3.07it/s]  8%|▊         | 220/2836 [01:27<14:13,  3.06it/s]  8%|▊         | 221/2836 [01:27<14:21,  3.03it/s]  8%|▊         | 221/2836 [01:27<14:22,  3.03it/s]  8%|▊         | 222/2836 [01:28<14:59,  2.91it/s]  8%|▊         | 222/2836 [01:28<15:00,  2.90it/s]  8%|▊         | 223/2836 [01:28<14:29,  3.00it/s]  8%|▊         | 223/2836 [01:28<14:29,  3.01it/s]  8%|▊         | 224/2836 [01:28<14:18,  3.04it/s]  8%|▊         | 224/2836 [01:28<14:18,  3.04it/s]  8%|▊         | 225/2836 [01:29<14:39,  2.97it/s]  8%|▊         | 225/2836 [01:29<14:39,  2.97it/s]  8%|▊         | 226/2836 [01:29<14:26,  3.01it/s]  8%|▊         | 226/2836 [01:29<14:26,  3.01it/s]  8%|▊         | 227/2836 [01:29<15:02,  2.89it/s]  8%|▊         | 227/2836 [01:29<15:02,  2.89it/s]  8%|▊         | 228/2836 [01:30<16:04,  2.70it/s]  8%|▊         | 228/2836 [01:30<16:04,  2.70it/s]  8%|▊         | 229/2836 [01:30<15:55,  2.73it/s]  8%|▊         | 229/2836 [01:30<15:55,  2.73it/s]  8%|▊         | 230/2836 [01:31<17:48,  2.44it/s]  8%|▊         | 230/2836 [01:31<17:48,  2.44it/s]  8%|▊         | 231/2836 [01:31<17:31,  2.48it/s]  8%|▊         | 231/2836 [01:31<17:31,  2.48it/s]  8%|▊         | 232/2836 [01:31<16:12,  2.68it/s]  8%|▊         | 232/2836 [01:31<16:12,  2.68it/s]  8%|▊         | 233/2836 [01:32<15:42,  2.76it/s]  8%|▊         | 233/2836 [01:32<15:43,  2.76it/s]  8%|▊         | 234/2836 [01:32<15:57,  2.72it/s]  8%|▊         | 234/2836 [01:32<15:57,  2.72it/s]  8%|▊         | 235/2836 [01:32<15:07,  2.87it/s]  8%|▊         | 235/2836 [01:32<15:08,  2.86it/s]  8%|▊         | 236/2836 [01:33<15:22,  2.82it/s]  8%|▊         | 236/2836 [01:33<15:23,  2.82it/s]  8%|▊         | 237/2836 [01:33<15:28,  2.80it/s]  8%|▊         | 237/2836 [01:33<15:28,  2.80it/s]  8%|▊         | 238/2836 [01:33<16:22,  2.64it/s]  8%|▊         | 238/2836 [01:33<16:28,  2.63it/s]  8%|▊         | 239/2836 [01:34<16:12,  2.67it/s]  8%|▊         | 239/2836 [01:34<16:10,  2.68it/s]  8%|▊         | 240/2836 [01:34<16:31,  2.62it/s]  8%|▊         | 240/2836 [01:34<16:32,  2.62it/s]  8%|▊         | 241/2836 [01:35<17:06,  2.53it/s]  8%|▊         | 241/2836 [01:35<17:08,  2.52it/s]  9%|▊         | 242/2836 [01:35<16:23,  2.64it/s]  9%|▊         | 242/2836 [01:35<16:24,  2.64it/s]  9%|▊         | 243/2836 [01:35<15:24,  2.80it/s]  9%|▊         | 243/2836 [01:35<15:25,  2.80it/s]  9%|▊         | 244/2836 [01:36<15:59,  2.70it/s]  9%|▊         | 244/2836 [01:36<15:59,  2.70it/s]  9%|▊         | 245/2836 [01:36<15:02,  2.87it/s]  9%|▊         | 245/2836 [01:36<15:02,  2.87it/s]  9%|▊         | 246/2836 [01:36<15:46,  2.74it/s]  9%|▊         | 246/2836 [01:36<15:47,  2.73it/s]  9%|▊         | 247/2836 [01:37<16:25,  2.63it/s]  9%|▊         | 247/2836 [01:37<16:25,  2.63it/s]  9%|▊         | 248/2836 [01:37<15:58,  2.70it/s]  9%|▊         | 248/2836 [01:37<15:58,  2.70it/s]  9%|▉         | 249/2836 [01:38<16:05,  2.68it/s]  9%|▉         | 249/2836 [01:38<16:06,  2.68it/s]  9%|▉         | 250/2836 [01:38<16:00,  2.69it/s]  9%|▉         | 250/2836 [01:38<16:00,  2.69it/s]  9%|▉         | 251/2836 [01:38<15:20,  2.81it/s]  9%|▉         | 251/2836 [01:38<15:20,  2.81it/s]  9%|▉         | 252/2836 [01:39<16:15,  2.65it/s]  9%|▉         | 252/2836 [01:39<16:15,  2.65it/s]  9%|▉         | 253/2836 [01:39<15:29,  2.78it/s]  9%|▉         | 253/2836 [01:39<15:29,  2.78it/s]  9%|▉         | 254/2836 [01:39<14:50,  2.90it/s]  9%|▉         | 254/2836 [01:39<14:50,  2.90it/s]  9%|▉         | 255/2836 [01:40<15:39,  2.75it/s]  9%|▉         | 255/2836 [01:40<15:40,  2.75it/s]  9%|▉         | 256/2836 [01:40<14:56,  2.88it/s]  9%|▉         | 256/2836 [01:40<14:56,  2.88it/s]  9%|▉         | 257/2836 [01:40<16:01,  2.68it/s]  9%|▉         | 257/2836 [01:40<16:01,  2.68it/s]  9%|▉         | 258/2836 [01:41<15:53,  2.70it/s]  9%|▉         | 258/2836 [01:41<15:53,  2.70it/s]  9%|▉         | 259/2836 [01:41<15:32,  2.76it/s]  9%|▉         | 259/2836 [01:41<15:32,  2.76it/s]  9%|▉         | 260/2836 [01:42<15:36,  2.75it/s]  9%|▉         | 260/2836 [01:42<15:37,  2.75it/s]  9%|▉         | 261/2836 [01:42<14:48,  2.90it/s]  9%|▉         | 261/2836 [01:42<14:48,  2.90it/s]  9%|▉         | 262/2836 [01:42<14:26,  2.97it/s]  9%|▉         | 262/2836 [01:42<14:26,  2.97it/s]WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1066740 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1066741 closing signal SIGINT
  9%|▉         | 262/2836 [01:42<16:51,  2.54it/s]
Traceback (most recent call last):
  File "/home/jingyan/Documents/sign_language_rgb/./tools/train_ddp.py", line 183, in <module>
    main()
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/jingyan/Documents/sign_language_rgb/./tools/train_ddp.py", line 88, in main
    mean_loss, hyp_train, gt_train= trainer.do_train(model, loss_fn, train_loader, opt, getattr(cfg, 'data_excluded', []))
  File "/home/jingyan/Documents/sign_language_rgb/src/csi_sign_language/engines/trainner.py", line 71, in do_train
    self._backward_and_update(loss, opt)
  File "/home/jingyan/Documents/sign_language_rgb/src/csi_sign_language/engines/trainner.py", line 108, in _backward_and_update
    loss.backward()
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
  9%|▉         | 262/2836 [01:43<16:52,  2.54it/s]
Traceback (most recent call last):
  File "/home/jingyan/Documents/sign_language_rgb/./tools/train_ddp.py", line 183, in <module>
    main()
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/jingyan/Documents/sign_language_rgb/./tools/train_ddp.py", line 88, in main
    mean_loss, hyp_train, gt_train= trainer.do_train(model, loss_fn, train_loader, opt, getattr(cfg, 'data_excluded', []))
  File "/home/jingyan/Documents/sign_language_rgb/src/csi_sign_language/engines/trainner.py", line 71, in do_train
    self._backward_and_update(loss, opt)
  File "/home/jingyan/Documents/sign_language_rgb/src/csi_sign_language/engines/trainner.py", line 108, in _backward_and_update
    loss.backward()
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/jingyan/anaconda3/envs/dl/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 241, in launch_agent
    result = agent.run()
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 723, in run
    result = self._invoke_run(role)
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/jingyan/anaconda3/envs/dl/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 1066706 got signal: 2
