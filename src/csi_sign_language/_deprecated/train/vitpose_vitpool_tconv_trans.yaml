seed: 3407
device: cuda
epoch: 80
#-1 when we don want message out
message_interval: 100
num_workers: 10
batch_size: 2
vocab_size: 1296

#if continuos read model
load_weights: True
is_resume: False
checkpoint: outputs/train/2024-03-26_19-26-37/train_x3d_trans/checkpoint.pt

data_excluded: ["13April_2011_Wednesday_tagesschau_default-14",]

model:
  _target_: ${csi}.models.slr_ctc_baseline.SLRModel
  loss_temp: 8
  loss_weight: [1.0, 0., 0.]
  backbone: 
    _target_: ${csi}.modules.slr_base.base_stream.BaseStream
    encoder: 
      _target_: ${csi}.modules.slr_base.vitpose_encoder.VitPoseEncoder
      img_size: 192
      color_range: [0, 1]
      cfg_path: resources/vitpose/td-hm_ViTPose-small_8xb64-210e_coco-256x192.py
      checkpoint: resources/vitpose/td-hm_ViTPose-small_8xb64-210e_coco-256x192-62d7a712_20230314.pth
      drop_path_rate: 0.5
      freeze_vitpose: False
    neck:
      _target_: ${csi}.modules.tconv.TemporalConv1D
      input_size: 384
      out_size: 1024
      bottleneck_size:  512
      conv_type: ['K5', 'P2', 'K5', 'P2']
    decoder:
      _target_: ${csi}.modules.slr_base.decoders.TransformerDecoder
      n_class: ${train.vocab_size}
      d_model: 1024
      n_heads: 8
      n_layers: 6
      d_feedforward: 2048

optimizer:
  _target_: torch.optim.Adam
  lr: 2e-6
  weight_decay: 0.0001

lr_scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 15
  gamma: 0.5

trainner:
  _target_: ${csi}.engines.trainner.Trainner
  device: ${train.device}
  message_interval: ${train.message_interval}

inferencer:
  _target_: ${csi}.engines.inferencer.Inferencer
  device: ${train.device}

collate_fn: 
  _target_: ${csi}.data.dataset.phoenix14.CollateFn

transform_train: 
      _target_: ${T}.Compose
      transforms: 
        #process video data
      - _target_: ${CT}.common.ApplyByKey
        key: video
        transforms:
        - _target_: ${CT}.common.ToTensor
          dtype: float32
        - _target_: ${CT}.common.TemporalAug
          t_min: 0.8
          t_max: 1.2
        - _target_: ${CT}.common.Rescale
          input: [0., 255.]
          output: [0., 1.]
        - _target_: ${CT}.common.Rearrange
          pattern: "t h w c -> t c h w"
        - _target_: ${T}.RandomResizedCrop
          size: 224
          scale: [0.7, 1.0]
          ratio: [0.75, 1.33333333333]
          antialias: True
        - _target_: ${T}.Resize
          size: 192
        - _target_: ${CT}.t_tensor.ColorJitter
          brightness: 0.4
          contrast: 0.4
          saturation: 0.4
          hue: 0.1
          p: 0.5
        #process gloss data
      - _target_: ${CT}.common.ApplyByKey
        key: gloss
        transforms:
        - _target_: ${CT}.common.ToTensor

transform_val: 
      _target_: ${T}.Compose
      transforms: 
      - _target_: ${CT}.common.ApplyByKey
        key: video
        transforms:
        - _target_: ${CT}.common.ToTensor
          dtype: float32
        - _target_: ${CT}.common.Rearrange
          pattern: "t h w c -> t c h w"
        - _target_: ${CT}.common.Rescale
          input: [0., 255.]
          output: [0., 1.]
        - _target_: ${T}.CenterCrop
          size: 224
        - _target_: ${T}.Resize
          size: 192
        # - _target_: ${CT}.common.Rearrange
        #   pattern: "t c h w -> t h w c"
      - _target_: ${CT}.common.ApplyByKey
        key: gloss
        transforms:
        - _target_: ${CT}.common.ToTensor
  
train_set: 
  _target_: ${csi}.data.dataset.phoenix14.MyPhoenix14Dataset
  data_root: ${ph14.lmdb_root}
  subset: multisigner
  mode: train
  transform: ${train.transform_train}

val_set: 
  _target_: ${csi}.data.dataset.phoenix14.MyPhoenix14Dataset
  data_root: ${ph14.lmdb_root}
  subset: multisigner
  mode: dev
  transform: ${train.transform_val}


train_loader:
  _target_: torch.utils.data.DataLoader
  batch_size: ${train.batch_size}
  num_workers: ${train.num_workers}
  shuffle: true
  dataset: ${train.train_set}
  collate_fn: ${train.collate_fn}

val_loader:
  _target_: torch.utils.data.DataLoader
  batch_size: ${train.batch_size}
  num_workers: ${train.num_workers}
  dataset: ${train.val_set}
  collate_fn: ${train.collate_fn}
