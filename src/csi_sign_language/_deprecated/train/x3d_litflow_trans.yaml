
hydra:
  run: 
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}/${hydra.job.name}_${description}
  
description: x3d_trans

csi: csi_sign_language
transform: torchvision.transforms
T: torchvision.transforms
CT: csi_sign_language.data.transforms

phoenix14_root: preprocessed/ph14_lmdb

seed: 3407
device: cuda
epoch: 80
#-1 when we don want message out
message_interval: 100
non_block: False
pin_memory: False
num_workers: 6
batch_size: 3
vocab_size: 1296

#if continuos read model
load_weights: False
is_resume: False
checkpoint: outputs/train/2024-03-11_17-13-04/train_x3d_with_flownet/checkpoint.pt

model:
  _target_: ${csi}.models.slr_ctc_baseline.SLRModel
  loss_temp: 8
  loss_weight: [1.0, 0., 0.]
  backbone: 
    _target_: ${csi}.modules.slr_base.base_stream.BaseStream
    encoder: 
      _target_: ${csi}.modules.slr_base.fusion_encoders.X3DFlowEncoder
      freeze_flownet: True
      freeze_x3d: False
      color_range: [0., 1.]
      x3d_type: x3d_s
      flownet_checkpoint: resources/network-sintel.pytorch
      fusion_layers:
        - [24, 0.5, 81]
        - [48, 0.5, 81]
        - [96, 0.5, 81]
        - [192, 0.5, 81]
      x3d_header:
        _target_: ${csi}.modules.x3d.Header
        input_channels: 192
        out_channels: 512
        bottleneck_channels: 432
    neck:
      _target_: ${csi}.modules.tconv.TemporalConv1D
      input_size: 512
      out_size: 512
      bottleneck_size:  256
      conv_type: ['K3', 'P2', 'K3', 'P2']
    decoder:
      _target_: ${csi}.modules.slr_base.decoders.TransformerDecoder
      n_class: ${vocab_size}
      d_model: 512
      n_heads: 8
      n_layers: 6
      d_feedforward: 1024

optimizer:
  _target_: torch.optim.Adam
  lr: 1e-4
  weight_decay: 0.0001

lr_scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 40
  gamma: 0.8

trainner:
  _target_: ${csi}.engines.trainner.Trainner
  device: ${device}
  message_interval: ${message_interval}

inferencer:
  _target_: ${csi}.engines.inferencer.Inferencer
  device: ${device}

data:
  excluded: ["13April_2011_Wednesday_tagesschau_default-14",]
  subset: multisigner
  collate_fn: 
    _target_: ${csi}.data.dataset.phoenix14.CollateFn

  transform_train: 
        _target_: ${T}.Compose
        transforms: 
          #process video data
        - _target_: ${CT}.common.ApplyByKey
          key: video
          transforms:
          - _target_: ${CT}.common.ToTensor
            dtype: float32
          - _target_: ${CT}.common.Rescale
            input: [0., 255.]
            output: [0., 1.]
          - _target_: ${CT}.common.Rearrange
            pattern: "t h w c -> t c h w"
          - _target_: ${T}.RandomResizedCrop
            size: 224
            scale: [0.7, 1.0]
            ratio: [0.75, 1.33333333333]
            antialias: True
          - _target_: ${T}.Resize
            size: 160
            #the input of color jitter should be rescaled into 0.-1.
          - _target_: ${CT}.t_tensor.ColorJitter
            brightness: 0.4
            contrast: 0.4
            saturation: 0.4
            hue: 0.1
            p: 0.5
          #process gloss data
        - _target_: ${CT}.common.ApplyByKey
          key: gloss
          transforms:
          - _target_: ${CT}.common.ToTensor

  transform_val: 
        _target_: ${T}.Compose
        transforms: 
        - _target_: ${CT}.common.ApplyByKey
          key: video
          transforms:
          - _target_: ${CT}.common.ToTensor
            dtype: float32
          - _target_: ${CT}.common.Rearrange
            pattern: "t h w c -> t c h w"
          - _target_: ${CT}.common.Rescale
            input: [0., 255.]
            output: [0., 1.]
          - _target_: ${T}.CenterCrop
            size: 224
          - _target_: ${T}.Resize
            size: 160
          # - _target_: ${CT}.common.Rearrange
          #   pattern: "t c h w -> t h w c"
        - _target_: ${CT}.common.ApplyByKey
          key: gloss
          transforms:
          - _target_: ${CT}.common.ToTensor
    
  train_set: 
    _target_: ${csi}.data.dataset.phoenix14.MyPhoenix14Dataset
    data_root: ${phoenix14_root}
    subset: ${data.subset}
    mode: train
    transform: ${data.transform_train}

  val_set: 
    _target_: ${csi}.data.dataset.phoenix14.MyPhoenix14Dataset
    data_root: ${phoenix14_root}
    subset: ${data.subset}
    mode: dev
    transform: ${data.transform_val}


  train_loader:
    _target_: torch.utils.data.DataLoader
    batch_size: ${batch_size}
    num_workers: ${num_workers}
    pin_memory: ${pin_memory}
    shuffle: true
    dataset: ${data.train_set}
    collate_fn: ${data.collate_fn}

  val_loader:
    _target_: torch.utils.data.DataLoader
    batch_size: ${batch_size}
    num_workers: ${num_workers}
    pin_memory: ${pin_memory}
    dataset: ${data.val_set}
    collate_fn: ${data.collate_fn}
